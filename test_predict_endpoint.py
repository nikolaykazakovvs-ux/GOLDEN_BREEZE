"""
–¢–µ—Å—Ç /predict endpoint —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ XAUUSD.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–æ–µ inference Direction LSTM –º–æ–¥–µ–ª–∏.
"""
import subprocess
import time
import requests
import json
import sys


# –ü—Ä–∏–º–µ—Ä 50 —Å–≤–µ—á–µ–π XAUUSD M5 (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è LSTM —Å seq_len=50)
SAMPLE_CANDLES = [
    {"timestamp": "2024-01-01 00:00:00", "open": 2065.5, "high": 2067.0, "low": 2064.0, "close": 2066.5, "volume": 1200},
    {"timestamp": "2024-01-01 00:05:00", "open": 2066.5, "high": 2068.5, "low": 2065.5, "close": 2067.0, "volume": 1350},
    {"timestamp": "2024-01-01 00:10:00", "open": 2067.0, "high": 2069.0, "low": 2066.0, "close": 2068.0, "volume": 1400},
    {"timestamp": "2024-01-01 00:15:00", "open": 2068.0, "high": 2070.0, "low": 2067.0, "close": 2069.0, "volume": 1500},
    {"timestamp": "2024-01-01 00:20:00", "open": 2069.0, "high": 2071.0, "low": 2068.0, "close": 2070.0, "volume": 1600},
    {"timestamp": "2024-01-01 00:25:00", "open": 2070.0, "high": 2072.0, "low": 2069.0, "close": 2071.0, "volume": 1650},
    {"timestamp": "2024-01-01 00:30:00", "open": 2071.0, "high": 2073.0, "low": 2070.0, "close": 2072.0, "volume": 1700},
    {"timestamp": "2024-01-01 00:35:00", "open": 2072.0, "high": 2074.0, "low": 2071.0, "close": 2073.0, "volume": 1750},
    {"timestamp": "2024-01-01 00:40:00", "open": 2073.0, "high": 2075.0, "low": 2072.0, "close": 2074.0, "volume": 1800},
    {"timestamp": "2024-01-01 00:45:00", "open": 2074.0, "high": 2076.0, "low": 2073.0, "close": 2075.0, "volume": 1850},
] * 5  # –î—É–±–ª–∏—Ä—É–µ–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 50 —Å–≤–µ—á–µ–π


def test_predict_endpoint():
    """–¢–µ—Å—Ç /predict endpoint —Å GPU inference."""
    
    # –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
    print("üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ...")
    server_process = subprocess.Popen(
        [sys.executable, "-m", "aimodule.server.local_ai_gateway"],
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1
    )
    
    # –û–∂–∏–¥–∞–Ω–∏–µ —Å—Ç–∞—Ä—Ç–∞
    print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ —Å—Ç–∞—Ä—Ç–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
    server_ready = False
    for i in range(15):
        try:
            response = requests.get("http://127.0.0.1:5005/health", timeout=1)
            if response.status_code == 200:
                server_ready = True
                print("‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω!")
                break
        except requests.exceptions.ConnectionError:
            pass
        time.sleep(1)
    
    if not server_ready:
        print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è!")
        server_process.terminate()
        return False
    
    try:
        # –¢–µ—Å—Ç /predict endpoint
        print("\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ /predict endpoint:")
        print(f"   - –û—Ç–ø—Ä–∞–≤–∫–∞ {len(SAMPLE_CANDLES)} —Å–≤–µ—á–µ–π XAUUSD M5")
        
        payload = {
            "symbol": "XAUUSD",
            "timeframe": "M5",
            "candles": SAMPLE_CANDLES[:50]  # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–æ–≤–Ω–æ 50 —Å–≤–µ—á–µ–π
        }
        
        response = requests.post(
            "http://127.0.0.1:5005/predict",
            json=payload,
            timeout=10
        )
        
        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}: {response.text}")
            return False
        
        prediction = response.json()
        print("\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç prediction:")
        print(json.dumps(prediction, indent=2, ensure_ascii=False))
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–µ–π
        required_keys = ["symbol", "timeframe", "regime", "direction", "confidence", "action"]
        missing_keys = [key for key in required_keys if key not in prediction]
        
        if missing_keys:
            print(f"\n‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏: {missing_keys}")
            return False
        
        print("\nüîç –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:")
        print(f"   - Symbol: {prediction['symbol']}")
        print(f"   - Timeframe: {prediction['timeframe']}")
        print(f"   - Regime: {prediction['regime']}")
        print(f"   - Direction: {prediction['direction']}")
        print(f"   - Confidence: {prediction['confidence']:.3f}")
        print(f"   - Action: {prediction['action']}")
        
        if prediction.get("reasons"):
            print(f"   - Reasons: {', '.join(prediction['reasons'])}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ confidence
        conf = prediction.get("confidence", 0)
        if 0.0 <= conf <= 1.0:
            print(f"\n‚úÖ Confidence –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {conf:.3f}")
        else:
            print(f"\n‚ö†Ô∏è Confidence –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0, 1]: {conf:.3f}")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        print("\nüõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...")
        server_process.terminate()
        server_process.wait(timeout=5)
        print("‚úÖ –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")


if __name__ == "__main__":
    success = test_predict_endpoint()
    sys.exit(0 if success else 1)
