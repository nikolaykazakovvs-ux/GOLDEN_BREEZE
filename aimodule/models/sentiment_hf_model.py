# aimodule/models/sentiment_hf_model.py

"""
–õ–æ–∫–∞–ª—å–Ω–∞—è sentiment –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ HuggingFace transformers.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π.
"""

from typing import Optional
from pathlib import Path
import numpy as np

try:
    from transformers import AutoTokenizer, AutoModelForSequenceClassification
    import torch
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    print("‚ö†Ô∏è  transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, sentiment HF –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")


class HFLocalSentimentModel:
    """
    –õ–æ–∫–∞–ª—å–Ω–∞—è sentiment –º–æ–¥–µ–ª—å –Ω–∞ –±–∞–∑–µ HuggingFace.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å:
    - cardiffnlp/twitter-roberta-base-sentiment-latest (–æ–±—â–∏–π sentiment)
    - –∏–ª–∏ ProsusAI/finbert (—Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π sentiment)
    
    –ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ —Å–∫–∞—á–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –≤ ~/.cache/huggingface
    """
    
    def __init__(
        self,
        model_name: str = "cardiffnlp/twitter-roberta-base-sentiment-latest"
    ):
        """
        Args:
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏ –Ω–∞ HuggingFace Hub
        """
        self.model_name = model_name
        self.model = None
        self.tokenizer = None
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        if not TRANSFORMERS_AVAILABLE:
            print("‚ö†Ô∏è  HFLocalSentimentModel –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: transformers –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return
        
        try:
            self._load_model()
        except Exception as e:
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å sentiment –º–æ–¥–µ–ª—å: {e}")
            print("   –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install transformers torch")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞."""
        print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ sentiment –º–æ–¥–µ–ª–∏: {self.model_name}")
        print("   (–ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–∫–∞—á–∞–Ω–∞)")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
        self.model.to(self.device)
        self.model.eval()
        
        print("‚úÖ Sentiment –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    def predict(self, text: str) -> float:
        """
        –ê–Ω–∞–ª–∏–∑ sentiment —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–æ–≤–æ—Å—Ç—å, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏ —Ç.–¥.)
            
        Returns:
            float –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1.0, 1.0]
            - -1.0: –æ—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π
            - 0.0: –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π
            - 1.0: –æ—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π
        """
        if not TRANSFORMERS_AVAILABLE or self.model is None:
            return 0.0
        
        if not text or len(text.strip()) < 3:
            return 0.0
        
        try:
            # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                truncation=True,
                max_length=512,
                padding=True
            ).to(self.device)
            
            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            probs = torch.softmax(logits, dim=-1).cpu().numpy().flatten()
            
            # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            # –§–æ—Ä–º–∞—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏:
            # - twitter-roberta: [negative, neutral, positive]
            # - finbert: [positive, negative, neutral]
            
            if "twitter-roberta" in self.model_name.lower():
                # [negative, neutral, positive]
                negative, neutral, positive = probs[0], probs[1], probs[2]
            elif "finbert" in self.model_name.lower():
                # [positive, negative, neutral]
                positive, negative, neutral = probs[0], probs[1], probs[2]
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º [negative, neutral, positive]
                negative, neutral, positive = probs[0], probs[1] if len(probs) > 1 else 0, probs[2] if len(probs) > 2 else 0
            
            # –†–∞—Å—á—ë—Ç sentiment score –≤ [-1, 1]
            sentiment = positive - negative
            
            return float(np.clip(sentiment, -1.0, 1.0))
        
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ sentiment: {e}")
            return 0.0
    
    def predict_batch(self, texts: list[str]) -> list[float]:
        """
        –ê–Ω–∞–ª–∏–∑ sentiment –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ (–±–∞—Ç—á-–∏–Ω—Ñ–µ—Ä–µ–Ω—Å).
        
        Args:
            texts: —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤
            
        Returns:
            —Å–ø–∏—Å–æ–∫ sentiment scores –≤ [-1.0, 1.0]
        """
        if not texts:
            return []
        
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
        # –ú–æ–∂–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ –±–∞—Ç—á-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é
        return [self.predict(text) for text in texts]
    
    def predict_average(self, texts: list[str]) -> float:
        """
        –°—Ä–µ–¥–Ω–∏–π sentiment –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤.
        
        Args:
            texts: —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –¥–µ–Ω—å)
            
        Returns:
            —Å—Ä–µ–¥–Ω–∏–π sentiment –≤ [-1.0, 1.0]
        """
        if not texts:
            return 0.0
        
        scores = self.predict_batch(texts)
        valid_scores = [s for s in scores if s != 0.0]
        
        if not valid_scores:
            return 0.0
        
        return float(np.mean(valid_scores))


# Singleton instance (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
_hf_sentiment_instance = None


def get_hf_sentiment_model(
    model_name: str = "cardiffnlp/twitter-roberta-base-sentiment-latest"
) -> HFLocalSentimentModel:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ singleton instance HF sentiment –º–æ–¥–µ–ª–∏.
    
    Args:
        model_name: –∏–º—è –º–æ–¥–µ–ª–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –≤—ã–∑–æ–≤–µ)
        
    Returns:
        HFLocalSentimentModel instance
    """
    global _hf_sentiment_instance
    
    if _hf_sentiment_instance is None:
        _hf_sentiment_instance = HFLocalSentimentModel(model_name=model_name)
    
    return _hf_sentiment_instance
